<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"flat"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":true,"comments":{"style":"tabs","active":"gitalk","storage":true,"lazyload":false,"nav":null,"activeClass":"gitalk"},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="本文介绍了一种机器学习辅助神经疾病诊断的方法：network atlas-guided feature selection（基于网络连接图谱的特征选择）。 本文是对NAGFS的github库中run_demo.m文件、simulateData.m文件的代码解读。">
<meta property="og:type" content="article">
<meta property="og:title" content="NAGFS(2)示例代码解读">
<meta property="og:url" content="http://example.com/2023/12/28/NAGFS-CODE-INTERPRETATION/index.html">
<meta property="og:site_name" content="RaspberryCoke">
<meta property="og:description" content="本文介绍了一种机器学习辅助神经疾病诊断的方法：network atlas-guided feature selection（基于网络连接图谱的特征选择）。 本文是对NAGFS的github库中run_demo.m文件、simulateData.m文件的代码解读。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/2023/12/28/NAGFS-CODE-INTERPRETATION/TopFeature.png">
<meta property="og:image" content="http://example.com/2023/12/28/NAGFS-CODE-INTERPRETATION/ATLAS1.png">
<meta property="og:image" content="http://example.com/2023/12/28/NAGFS-CODE-INTERPRETATION/ind_Nf.png">
<meta property="og:image" content="http://example.com/2023/12/28/NAGFS-CODE-INTERPRETATION/1.png">
<meta property="og:image" content="http://example.com/2023/12/28/NAGFS-CODE-INTERPRETATION/2.png">
<meta property="article:published_time" content="2023-12-28T12:40:15.000Z">
<meta property="article:modified_time" content="2024-01-27T13:59:45.770Z">
<meta property="article:author" content="树莓可乐">
<meta property="article:tag" content="AI">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2023/12/28/NAGFS-CODE-INTERPRETATION/TopFeature.png">

<link rel="canonical" href="http://example.com/2023/12/28/NAGFS-CODE-INTERPRETATION/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>NAGFS(2)示例代码解读 | RaspberryCoke</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">RaspberryCoke</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">学习记录</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

  <a href="https://github.com/RaspberryCoke" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/12/28/NAGFS-CODE-INTERPRETATION/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="树莓可乐">
      <meta itemprop="description" content="认真但不沉重，坚定却仍然轻快">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="RaspberryCoke">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          NAGFS(2)示例代码解读
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2023-12-28 20:40:15" itemprop="dateCreated datePublished" datetime="2023-12-28T20:40:15+08:00">2023-12-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-01-27 21:59:45" itemprop="dateModified" datetime="2024-01-27T21:59:45+08:00">2024-01-27</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>本文介绍了一种机器学习辅助神经疾病诊断的方法：network atlas-guided
feature selection（基于网络连接图谱的特征选择）。
本文是对NAGFS的github库中run_demo.m文件、simulateData.m文件的代码解读。</p>
<span id="more"></span>
<p>仓库链接：https://github.com/basiralab/NAGFS</p>
<pre><code>一些被笔者定义的基础数据：
    1. class1的人数：C1=13（健康组）,
    2. class2的人数：C2=17（患病组）,
    3. 关心的脑区域的个数：m=23,
    4. 总人数：N=C1+C2=30,
    5. 用来进行分类的特征数量Nf = 5,
    6. 健康组的脑区原始数据(C1*m*m)：dataC1,
    7. 患病组的脑区原始数据(C2*m*m)：dataC2,
    8. 拼接所有人的原始数据data1=[dataC1,dataC2]。</code></pre>
<p><strong>以上数据贯穿全文，请读者牢记。</strong>
<em>注：阅读本文需要对论文有一定的了解。</em> # 随机生成原始数据</p>
<p>该程序仅为示例程序，并未直接使用ABIDE中给出的数据。因此需要先生成数据。
先定义两个高斯分布（正态分布），随后交给simulateData生成随机数据。</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">mu1 = <span class="number">0.9</span>; <span class="comment">% 定义第一个高斯分布的平均值和标准差，以此生成数据</span></span><br><span class="line">sigma1 = <span class="number">0.4</span>; </span><br><span class="line">mu2 = <span class="number">0.7</span>; <span class="comment">% 定义第二个高斯分布的平均值和标准差，以此生成数据</span></span><br><span class="line">sigma2 = <span class="number">0.6</span>; </span><br><span class="line"></span><br><span class="line">Nf = <span class="number">5</span>; <span class="comment">% 被选特征数量，自定义设置，重要参数</span></span><br><span class="line"></span><br><span class="line">displayResults = <span class="number">0</span>; <span class="comment">% 训练过程是否可视化</span></span><br><span class="line"></span><br><span class="line">[data] = simulateData(mu1, sigma1, mu2, sigma2); <span class="comment">% 生成数据</span></span><br></pre></td></tr></table></figure>
<p>从这里开始进入simulateData.m文件，以下是文件头定义的变量：
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[data]</span> = <span class="title">simulateData</span><span class="params">(mu1, sigma1, mu2, sigma2)</span></span></span><br><span class="line">rng(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% 每个个体的（对称的）特征矩阵（的上三角被拉成一维后）</span></span><br><span class="line"><span class="comment">% 被保存，Featurematrix：30*253。其中253=23*22/2。</span></span><br><span class="line">Featurematrix = [];</span><br><span class="line">Labels = [];<span class="comment">% 是否患病的标签，前C1为1，后C2个为-1.</span></span><br><span class="line">X =[];  <span class="comment">% 脑区原始数据被保存在data.X中。</span></span><br><span class="line">data =[];<span class="comment">% 函数返回值</span></span><br><span class="line">C1=<span class="number">13</span>;<span class="comment">% 健康人数</span></span><br><span class="line">C2=<span class="number">17</span>;<span class="comment">% 患病人数</span></span><br><span class="line">m=<span class="number">23</span>;<span class="comment">% 关心的脑区数</span></span><br><span class="line">N=C1+C2;<span class="comment">% 总人数</span></span><br></pre></td></tr></table></figure> 之后介绍随机生成函数： <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">dataC1 = normrnd(mu1,sigma1,[C1,m,m]);</span><br><span class="line">        <span class="comment">% 参数三：生成C1*m*m的三维矩阵。</span></span><br><span class="line">dataC2 = normrnd(mu2,sigma2,[C2,m,m]);</span><br><span class="line">        <span class="comment">% 参数三：生成C2*m*m的三维矩阵。</span></span><br><span class="line"></span><br><span class="line">data1 = [dataC1;dataC2];</span><br><span class="line"></span><br><span class="line"><span class="comment">% h1 = histogram(dataC1)生成直方图，直接注掉</span></span><br><span class="line"><span class="comment">% hold on</span></span><br><span class="line"><span class="comment">% h2 = histogram(dataC2)</span></span><br></pre></td></tr></table></figure> 之后是对矩阵的操作：
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:N <span class="comment">%循环遍历</span></span><br><span class="line">    <span class="comment">% 让对角元素全部为零</span></span><br><span class="line">    data1(<span class="built_in">i</span>,:,:)=<span class="built_in">squeeze</span>(data1(<span class="built_in">i</span>,:,:))-<span class="built_in">diag</span>(<span class="built_in">diag</span>(<span class="built_in">squeeze</span>(data1(<span class="built_in">i</span>,:,:)))); </span><br><span class="line">    <span class="comment">% 让矩阵变成一个对称矩阵</span></span><br><span class="line">    data1(<span class="built_in">i</span>,:,:) = (<span class="built_in">squeeze</span>(data1(<span class="built_in">i</span>,:,:))+(<span class="built_in">squeeze</span>(data1(<span class="built_in">i</span>,:,:)))&#x27;)./<span class="number">2</span>;</span><br><span class="line">    <span class="comment">% 提取上三角矩阵（不包含对角线），并保存在Featurematrix中</span></span><br><span class="line">    t = <span class="built_in">triu</span>(<span class="built_in">squeeze</span>(data1(<span class="built_in">i</span>,:,:)),<span class="number">1</span>); </span><br><span class="line">    x = t(<span class="built_in">find</span>(t)); </span><br><span class="line">    x1 = x.&#x27;;</span><br><span class="line">    Featurematrix = [Featurematrix;x1];</span><br><span class="line">    data.Featurematrix = Featurematrix;</span><br><span class="line">    <span class="comment">% 原始数据被保存在data.X中</span></span><br><span class="line">    data.X = data1;  </span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="comment">% 定义标签，用来表示是否患病</span></span><br><span class="line">data.Labels = [<span class="built_in">ones</span>(C1,<span class="number">1</span>);<span class="number">-1</span>*<span class="built_in">ones</span>(C2,<span class="number">1</span>)]; <span class="comment">% 前C1个全部是1，后C2个全部是-1.</span></span><br></pre></td></tr></table></figure> 从这里开始，回到run_demo.m文件. # 训练前准备 <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[data] = simulateData(mu1, sigma1, mu2, sigma2); <span class="comment">% 生成随机数据</span></span><br><span class="line"></span><br><span class="line">data_class1 = data.Featurematrix((data.Labels ==<span class="number">1</span>),:); <span class="comment">% 获取健康组</span></span><br><span class="line">data_class2 = data.Featurematrix((data.Labels ==<span class="number">-1</span>),:);  <span class="comment">% 获取患病组</span></span><br></pre></td></tr></table></figure>
这个程序采用了留一法，通过30次循环训练，完成整个训练过程。以下是初始化：
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">c = cvpartition(<span class="built_in">size</span>(data.Labels,<span class="number">1</span>),<span class="string">&#x27;LeaveOut&#x27;</span>);</span><br></pre></td></tr></table></figure> 代码使用 cvpartition 函数创建一个交叉验证分区对象 c，
该对象被配置为“<strong>留一法</strong>”交叉验证（Leave-One-Out
Cross-Validation）。 cvpartition
用于将数据集划分为训练和测试集，以便进行交叉验证。
具体来说，代码的含义是： 1. size(data.Labels, 1)
返回数据集中标签的数量，即数据集的样本数。 2. 'LeaveOut'
指定使用留一法交叉验证，即每次将一个样本作为测试集，其余作为训练集。</p>
<p><em>交叉验证：</em>
https://www.bilibili.com/video/BV1T84y167U9/?p=22&amp;share_source=copy_web&amp;vd_source=c72910ee4b0a1cbab1ee678c7650acc5</p>
<p>因此，对象 c 将包含有关如何将数据集划分为训练和测试集的信息，
可以在后续的交叉验证过程中使用。留一法交叉验证适用于小型数据集，
<strong>其中每个样本都被用作一次测试样本</strong>（故循环30次），以评估模型的性能。</p>
<p>随后，创建一个名为 ind_Nf 的二维矩阵，30x5。 所有元素被初始化为零。
这个矩阵通常用于存储每次循环训练时学习的5个最具有判别性的特征的索引。
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">% 创建了决策值向量，初始化为0，个数为所有的样本的数量</span></span><br><span class="line">decision_score = <span class="built_in">zeros</span>(<span class="built_in">size</span>(data.Labels,<span class="number">1</span>),<span class="number">1</span>); </span><br><span class="line"><span class="comment">% 获取data.X的维度</span></span><br><span class="line">[sz1,sz2,sz3] = <span class="built_in">size</span>(data.X);</span><br><span class="line">ind_Nf = <span class="built_in">zeros</span>(<span class="built_in">size</span>(data.Labels,<span class="number">1</span>),Nf);</span><br></pre></td></tr></table></figure>
随后，创建用来计算模型准确性的变量。这些变量会记录训练中的某些数据，并在最后的计算模型准确度时发挥作用：
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">dataFeatures = data.Featurematrix;</span><br><span class="line">test_Labels_vector = <span class="built_in">zeros</span>(<span class="built_in">size</span>(data.Labels,<span class="number">1</span>),<span class="number">1</span>); <span class="comment">% 真实标签</span></span><br><span class="line">accuracy = <span class="built_in">zeros</span>(<span class="built_in">size</span>(data.Labels,<span class="number">1</span>),<span class="number">1</span>) ; <span class="comment">% 准确度</span></span><br><span class="line">predicted_Labels = <span class="built_in">zeros</span>(<span class="built_in">size</span>(data.Labels,<span class="number">1</span>),<span class="number">1</span>); <span class="comment">% 预测标签</span></span><br></pre></td></tr></table></figure> # 训练过程 训练过程被包含在30次循环里。 <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> m = <span class="number">1</span> : c.NumObservations</span><br></pre></td></tr></table></figure></p>
<h2 id="创建训练集和测试集">创建训练集和测试集</h2>
<p>创建在本次循环中的训练集（29人）和测试集（1人）： <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">mm = num2str(m)</span><br><span class="line"></span><br><span class="line">testIndex = c.test(m);</span><br><span class="line">trainIndex = c.training(m);</span><br><span class="line">train_Labels = data.Labels(trainIndex);</span><br><span class="line">train_data = data.X(trainIndex,:,:);</span><br><span class="line">test_Label = data.Labels(testIndex);</span><br><span class="line">test_data = data.X(testIndex,:,:);</span><br><span class="line">test_Labels_vector(m) = test_Label;</span><br></pre></td></tr></table></figure>
其中，testIndex是一个30x1的向量，可能是这样的：
（0，0，0，1，0，0，0...） trainIndex是一个30x1的向量，可能是这样的：
（1，1，1，0，1，1，1...） train_Labels是一个29x1的向量，可能是这样的：
（1，1，1，-1，-1，1，-1...） train_Labels是一个29x23x23的向量。
test_Label是一个1x1的向量。 test_data是一个1x23x23的向量。
test_Labels_vector是用来收集30次训练循环中每次循环的测试集（1人）的标签，所以是30x1。该变量用来在后面计算算法的准确度。
## 执行NAGFS算法 <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[Atlas1,Atlas2,topFeaturesind] = </span><br><span class="line">    NAGFS(train_data,train_Labels,Nf,displayResults); </span><br><span class="line"><span class="comment">% train_data是29*23*23，train_Labels是29*1，Nf是5个index</span></span><br><span class="line"><span class="comment">% Atlas1是组1的23*23矩阵，Atlas2是组2的23*23矩阵</span></span><br><span class="line"><span class="comment">% 两个矩阵相减的绝对差最大的五个数字的index保存在topFeaturesind</span></span><br></pre></td></tr></table></figure>
注意：<strong>topFeaturesind是最核心的数据，它给出了用来分类的5个特征的index</strong>。其中的5个index指向了5个feature。在每次循环中，topFeaturesind很可能是不同的。随后将使用这5个feature完成本次循环的分类。
<img src="TopFeature.png" /><img src="ATLAS1.png" /><img
src="ATLAS2.png" /> ## 从原始数据抽取这5个特征
上个代码块中NAGFS函数已经给出了5个feature的索引下标，下面就从原始数据中提取这5个数。以下是先设置两个空值变量，用来保存。下一步再开始抽取数据。
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">%从原始数据中抽取出来训练集中每个人的对应的5个feature的具体值</span></span><br><span class="line">train_set = <span class="built_in">zeros</span>(<span class="built_in">length</span>(train_Labels),<span class="built_in">length</span>(dataFeatures));</span><br><span class="line">train_Nf = <span class="built_in">zeros</span>(<span class="built_in">length</span>(train_Labels),Nf);</span><br><span class="line"><span class="comment">% train_set：29*253，train_Nf：29*5</span></span><br><span class="line"><span class="comment">% train_set中包含了所有训练集的人的所有特征，</span></span><br><span class="line"><span class="comment">%   其中253=23*22/2，即取相关矩阵的上三角矩阵（不含对角线）。</span></span><br><span class="line"><span class="comment">% 随后从train_set提取用来分类的5个feature的具体值到train_Nf。</span></span><br></pre></td></tr></table></figure> 开始抽取5个特征： <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> r = <span class="number">1</span>: (<span class="built_in">length</span>(train_Labels)) <span class="comment">%对于每个人，进行一次循环</span></span><br><span class="line">        <span class="comment">% 取出第r个人的全部原始数据，为一个矩阵，23*23</span></span><br><span class="line">        train_subject = <span class="built_in">squeeze</span>(train_data(r,:,:));</span><br><span class="line">        train = <span class="built_in">triu</span>(train_subject);<span class="comment">%仅保留该矩阵的上三角，不包含主对角线</span></span><br><span class="line">        train_vect = [];</span><br><span class="line">        </span><br><span class="line">        <span class="comment">% 把上三角变成一条横线</span></span><br><span class="line">        <span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>: sz3</span><br><span class="line">            <span class="keyword">for</span> <span class="built_in">j</span> = (<span class="built_in">i</span>+<span class="number">1</span>): sz3</span><br><span class="line">                train_vect = [train_vect,train(<span class="built_in">i</span>,<span class="built_in">j</span>)]; <span class="comment">% Vectorize the upper triangular part of the training matrix</span></span><br><span class="line">            <span class="keyword">end</span></span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">% 把这条横线填到对应一行，train_set：29*253，29人的全部特征数据</span></span><br><span class="line">        train_set(r,:) = train_vect;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">% 抽取每个人对应的5个feature。train_Nf：29*5，29人，5个feature数据</span></span><br><span class="line">        <span class="keyword">for</span> h = <span class="number">1</span>: Nf</span><br><span class="line">            l = topFeaturesind(h);</span><br><span class="line">            train_Nf(r,h) = train_set(r,l);</span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">end</span></span><br></pre></td></tr></table></figure>
之后，测试集也如上抽取5个特征的数据： <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">% 对测试集做同样的操作</span></span><br><span class="line">test = <span class="built_in">triu</span>(<span class="built_in">squeeze</span>(test_data),<span class="number">1</span>);matrix</span><br><span class="line">test_vect = [];</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>: sz3</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">j</span> = (<span class="built_in">i</span>+<span class="number">1</span>): sz3</span><br><span class="line">        test_vect = [test_vect,test(<span class="built_in">i</span>,<span class="built_in">j</span>)];</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">test_Nf = [];</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">j</span> = <span class="number">1</span>: Nf</span><br><span class="line">    l = topFeaturesind(<span class="built_in">j</span>);</span><br><span class="line">    test_Nf = [test_Nf,test_vect(l)]; </span><br><span class="line">    <span class="comment">% test_Nf：1*5,一个人，5个feature</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure> ## 使用SVM进行分类
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">model = svmtrain(train_Labels,train_Nf);</span><br><span class="line">[predict_Labels, accuracy, decision_values] = </span><br><span class="line">        svmpredict(test_Label,test_Nf,model); </span><br><span class="line">predicted_Labels(m) = predict_Labels;</span><br><span class="line">test_Labels_vector(m) = test_Label;</span><br><span class="line">ind_Nf(m,:) = topFeaturesind;</span><br><span class="line"><span class="comment">% ind_Nf:30*5,一共有三十次循环，每次的5个feature的index</span></span><br></pre></td></tr></table></figure> 结束循环： <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">end</span> <span class="comment">%结束30次训练的循环，开头是 for m = 1 : c.NumObservations</span></span><br></pre></td></tr></table></figure> <img src="ind_Nf.png" /> #
计算模型准确度
模型的衡量标准有准确度（Accuracy），精确度（Precision）,敏感性（Sensitivity）,特异性（Specificity）。
准确度是指所有案例中被正确分类的比例。
精确度是指预测为患病的情况下，有多少是真的患病。
敏感性是指尽量不遗漏患病，特异性是指尽量不把正常人误诊为病人。</p>
<p>confusionmat 函数用于计算混淆矩阵（Confusion Matrix），
该矩阵是一种用于评估分类模型性能的表格。 confusionmat 返回的混淆矩阵 CM
是一个矩阵，其中的元素表示模型对样本的分类结果。 通常，混淆矩阵是一个
2x2 矩阵. 对于二元分类问题，它包含以下四个元素：</p>
<pre><code>CM = 
    [True Positive (TP)   False Negative (FN)
     False Positive (FP)   True Negative (TN)]</code></pre>
<ul>
<li>True Positive (TP): 模型正确地预测为正类别的样本数量。</li>
<li>False Negative (FN): 模型错误地预测为负类别的样本数量。</li>
<li>False Positive (FP): 模型错误地预测为正类别的样本数量。</li>
<li>True Negative (TN): 模型正确地预测为负类别的样本数量。</li>
</ul>
<p>这些元素可以用来计算各种性能指标，如准确度、精确度等。 accuracy =
sum(diag(CM)) / sum(CM( : )); % 计算准确度 precision = TP / (TP + FP); %
计算精确度 <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">% CM参数是30次测试的真实标签和预测标签，从而计算模型的准确度。</span></span><br><span class="line">CM = confusionmat(test_Labels_vector,predicted_Labels);</span><br><span class="line">True_Negative = CM(<span class="number">1</span>,<span class="number">1</span>);</span><br><span class="line">True_Positive = CM(<span class="number">2</span>,<span class="number">2</span>);</span><br><span class="line">False_Negative = CM(<span class="number">2</span>,<span class="number">1</span>);</span><br><span class="line">False_Positive = CM(<span class="number">1</span>,<span class="number">2</span>);</span><br><span class="line">Accuracy = (True_Positive + True_Negative)/(<span class="built_in">size</span>(data.Labels,<span class="number">1</span>)) * <span class="number">100</span>;</span><br><span class="line">Sensitivity = (True_Positive)/(True_Positive + False_Negative) * <span class="number">100</span>;</span><br><span class="line">Specificity = (True_Negative)/(True_Negative + False_Positive) * <span class="number">100</span>;</span><br></pre></td></tr></table></figure> # 可视化结果 <figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[J,H] = scoreFeaturesAcrossRuns(data,ind_Nf,Nf); </span><br><span class="line">pause(<span class="number">2</span>)</span><br><span class="line"><span class="built_in">figure</span></span><br><span class="line">imagesc(H),title(<span class="string">&#x27;NAGFS most discriminative</span></span><br><span class="line"><span class="string"> features across all cross-validation runs&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;Color&#x27;</span>,<span class="string">&#x27;b&#x27;</span>) </span><br><span class="line"></span><br><span class="line"><span class="built_in">figure</span></span><br><span class="line">h1 = histfit(data_class1(:),<span class="number">10</span>,<span class="string">&#x27;normal&#x27;</span>)</span><br><span class="line">h1(<span class="number">1</span>).FaceColor = [<span class="number">.8</span> <span class="number">.8</span> <span class="number">1</span>];</span><br><span class="line">h1(<span class="number">2</span>).Color = [<span class="number">.8</span> <span class="number">.8</span> <span class="number">1</span>];</span><br><span class="line">set(h1(<span class="number">1</span>),<span class="string">&#x27;FaceAlpha&#x27;</span>,<span class="number">.25</span>);</span><br><span class="line"></span><br><span class="line"><span class="built_in">hold</span> on</span><br><span class="line">h2 = histfit(data_class2(:),<span class="number">10</span>,<span class="string">&#x27;normal&#x27;</span>)</span><br><span class="line">h2(<span class="number">1</span>).FaceColor = [<span class="number">0.6350</span> <span class="number">0.0780</span> <span class="number">0.1840</span>];</span><br><span class="line">h2(<span class="number">2</span>).Color = [<span class="number">0.6350</span> <span class="number">0.0780</span> <span class="number">0.1840</span>];</span><br><span class="line">set(h2(<span class="number">1</span>),<span class="string">&#x27;FaceAlpha&#x27;</span>,<span class="number">.25</span>);</span><br><span class="line"></span><br><span class="line">title(<span class="string">&#x27;Class-specific simulated data distribution (2 classes)&#x27;</span>)</span><br><span class="line"><span class="built_in">hold</span> off</span><br></pre></td></tr></table></figure> 输出最后结果：
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">disp</span>([<span class="string">&#x27;Average accuracy = &#x27;</span> num2str(Accuracy) <span class="string">&#x27;%&#x27;</span>]);</span><br><span class="line"><span class="built_in">disp</span>([<span class="string">&#x27;Average sensitivity = &#x27;</span> num2str(Sensitivity) <span class="string">&#x27;%&#x27;</span>]);</span><br><span class="line"><span class="built_in">disp</span>([<span class="string">&#x27;Average Specificity = &#x27;</span> num2str(Specificity) <span class="string">&#x27;%&#x27;</span>]);</span><br></pre></td></tr></table></figure> 图示： <img src="1.png" /><img src="2.png" /><img
src="3.png" /></p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/AI/" rel="tag"># AI</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2023/12/28/NAGFS%E4%BB%A3%E7%A0%81readme%E8%A7%A3%E8%AF%BB/" rel="prev" title="NAGFS(1)readme解读">
      <i class="fa fa-chevron-left"></i> NAGFS(1)readme解读
    </a></div>
      <div class="post-nav-item">
    <a href="/2024/01/10/SIMLR_INTRODUCTION/" rel="next" title="NAGFS(3)SIMLR论文公式解读">
      NAGFS(3)SIMLR论文公式解读 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="gitalk-container"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%88%9B%E5%BB%BA%E8%AE%AD%E7%BB%83%E9%9B%86%E5%92%8C%E6%B5%8B%E8%AF%95%E9%9B%86"><span class="nav-number">1.</span> <span class="nav-text">创建训练集和测试集</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="树莓可乐"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">树莓可乐</p>
  <div class="site-description" itemprop="description">认真但不沉重，坚定却仍然轻快</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">8</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">标签</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">树莓可乐</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/pangu@4/dist/browser/pangu.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

<script src="/js/bookmark.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css">

<script>
NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : '1df548ccd4ff51da626e',
      clientSecret: 'f55ef8cc714f1f5c4189744a96597d7af58c45ec',
      repo        : 'RaspberryCoke.github.io',
      owner       : 'RaspberryCoke',
      admin       : ['RaspberryCoke'],
      id          : '22ccdb1f1c073363b51ec261f2bdfde3',
        language: 'zh-CN',
      distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script>

</body>
</html>
